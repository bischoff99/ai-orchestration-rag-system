{
  "name": "RAG Query Processing Pipeline",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "rag-query",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "RAG Query Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [240, 300],
      "webhookId": "rag-query-webhook"
    },
    {
      "parameters": {
        "jsCode": "// Process incoming query\nconst query = $json.query || $json.body?.query;\nconst collection = $json.collection || $json.body?.collection || 'default_docs';\nconst k = $json.k || $json.body?.k || 5;\nconst model = $json.model || $json.body?.model || 'llama-assistant';\n\nif (!query) {\n  return [{\n    json: {\n      error: 'Query is required',\n      status: 'error'\n    }\n  }];\n}\n\nreturn [{\n  json: {\n    query: query,\n    collection: collection,\n    k: k,\n    model: model,\n    timestamp: new Date().toISOString()\n  }\n}];"
      },
      "id": "process-query",
      "name": "Process Query",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [460, 300]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "error-condition",
              "leftValue": "={{ $json.status }}",
              "rightValue": "error",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "check-error",
      "name": "Check for Error",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [680, 300]
    },
    {
      "parameters": {
        "jsCode": "// Simulate ChromaDB search\n// In production, this would call your Python RAG API\nconst query = $json.query;\nconst collection = $json.collection;\nconst k = $json.k;\n\n// Simulate search results\nconst results = [\n  {\n    content: `Sample content related to: ${query}`,\n    metadata: {\n      source: 'sample_doc1.txt',\n      type: 'text'\n    },\n    score: 0.95\n  },\n  {\n    content: `Another relevant piece about: ${query}`,\n    metadata: {\n      source: 'sample_doc2.md',\n      type: 'markdown'\n    },\n    score: 0.87\n  }\n];\n\nreturn [{\n  json: {\n    results: results,\n    query: query,\n    collection: collection,\n    k: k\n  }\n}];"
      },
      "id": "chromadb-search",
      "name": "Search ChromaDB",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [900, 200]
    },
    {
      "parameters": {
        "jsCode": "// Format context from search results\nconst searchResults = $json.results || [];\nconst context = searchResults.map((result, index) => {\n  return `[${index + 1}] ${result.content || result.text || result.document}`;\n}).join('\\n\\n');\n\nconst sources = searchResults.map((result, index) => {\n  return {\n    index: index + 1,\n    source: result.metadata?.source || 'Unknown',\n    score: result.score || result.distance || 0\n  };\n});\n\nreturn [{\n  json: {\n    context: context,\n    sources: sources,\n    query: $json.query,\n    collection: $json.collection,\n    model: $json.model\n  }\n}];"
      },
      "id": "format-context",
      "name": "Format Context",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1120, 200]
    },
    {
      "parameters": {
        "jsCode": "// Simulate Ollama generation\n// In production, this would call Ollama API\nconst context = $json.context;\nconst query = $json.query;\nconst model = $json.model;\n\n// Simulate AI response\nconst response = `Based on the provided context, here's what I found about your question: \"${query}\"\n\n${context}\n\nThis is a simulated response from the ${model} model. In production, this would be generated by Ollama.`;\n\nreturn [{\n  json: {\n    response: response,\n    model: model,\n    query: query,\n    context: context\n  }\n}];"
      },
      "id": "ollama-generate",
      "name": "Generate with Ollama",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1340, 200]
    },
    {
      "parameters": {
        "jsCode": "// Format final response\nconst ollamaResponse = $json.response || $json.answer || 'No response generated';\nconst sources = $json.sources || [];\nconst query = $json.query;\n\nconst response = {\n  answer: ollamaResponse,\n  sources: sources,\n  query: query,\n  timestamp: new Date().toISOString(),\n  model: $json.model,\n  collection: $json.collection\n};\n\nreturn [{\n  json: response\n}];"
      },
      "id": "format-response",
      "name": "Format Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1560, 200]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}"
      },
      "id": "success-response",
      "name": "Success Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [1780, 200]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseCode": 400,
        "responseBody": "={\n  \"error\": \"{{ $json.error }}\",\n  \"status\": \"error\",\n  \"timestamp\": \"{{ new Date().toISOString() }}\"\n}"
      },
      "id": "error-response",
      "name": "Error Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [900, 400]
    }
  ],
  "connections": {
    "RAG Query Webhook": {
      "main": [
        [
          {
            "node": "Process Query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process Query": {
      "main": [
        [
          {
            "node": "Check for Error",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check for Error": {
      "main": [
        [
          {
            "node": "Search ChromaDB",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Error Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Search ChromaDB": {
      "main": [
        [
          {
            "node": "Format Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Context": {
      "main": [
        [
          {
            "node": "Generate with Ollama",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate with Ollama": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Response": {
      "main": [
        [
          {
            "node": "Success Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [],
  "triggerCount": 0,
  "updatedAt": "2025-01-15T10:30:00.000Z",
  "versionId": "1"
}